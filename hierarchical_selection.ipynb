{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Skill Selection\n",
    "\n",
    "If your scenario involves a large number of skills, however, you might need to consider Hierarchical Skill Selection. This is especially true if many of those skills are semantically similar, and you are looking to improve skill selection accuracy at the price of higher latency and complexity. In this pattern, you organize your skills into groups, and provide a description for each group. Your skill selection (either Generative or Semantic) first selects a group, and then performs a secondary search only among the skills in that group. While this is slower and would be expensive to parallelize, it reduces the complexity of the skill selection task into two smaller chunks, and frequently results in higher overall skill selection accuracy. Crafting and maintaining these skill groups takes time and effort, so this is not recommended as a technique to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import logging\n",
    "import numpy as np\n",
    " \n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tool groups with descriptions\n",
    "tool_groups = {\n",
    "    \"Computation\": {\n",
    "        \"description\": \"Tools related to mathematical computations and data analysis.\",\n",
    "        \"tools\": []\n",
    "    },\n",
    "    \"Automation\": {\n",
    "        \"description\": \"Tools that automate workflows and integrate different services.\",\n",
    "        \"tools\": []\n",
    "    },\n",
    "    \"Communication\": {\n",
    "        \"description\": \"Tools that facilitate communication and messaging.\",\n",
    "        \"tools\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tools\n",
    "@tool\n",
    "def query_wolfram_alpha(expression: str) -> str:\n",
    "    api_url = f\"https://api.wolframalpha.com/v1/result?i={requests.utils.quote(expression)}&appid={WOLFRAM_ALPHA_APP_ID}\"\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            raise ValueError(f\"Wolfram Alpha API Error: {response.status_code} - {response.text}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise ValueError(f\"Failed to query Wolfram Alpha: {e}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def trigger_zapier_webhook(zap_id: str, payload: dict) -> str:\n",
    "    \"\"\"\n",
    "    Trigger a Zapier webhook to execute a predefined Zap.\n",
    " \n",
    "    Args:\n",
    "        zap_id (str): The unique identifier for the Zap to be triggered.\n",
    "        payload (dict): The data to send to the Zapier webhook.\n",
    " \n",
    "    Returns:\n",
    "        str: Confirmation message upon successful triggering of the Zap.\n",
    " \n",
    "    Raises:\n",
    "        ValueError: If the API request fails or returns an error.\n",
    "    \"\"\"\n",
    "    zapier_webhook_url = f\"https://hooks.zapier.com/hooks/catch/{zap_id}/\"\n",
    "    try:\n",
    "        response = requests.post(zapier_webhook_url, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            return f\"Zapier webhook '{zap_id}' successfully triggered.\"\n",
    "        else:\n",
    "            raise ValueError(f\"Zapier API Error: {response.status_code} - {response.text}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise ValueError(f\"Failed to trigger Zapier webhook '{zap_id}': {e}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def send_slack_message(channel: str, message: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a message to a specified Slack channel.\n",
    " \n",
    "    Args:\n",
    "        channel (str): The Slack channel ID or name where the message will be sent.\n",
    "        message (str): The content of the message to send.\n",
    " \n",
    "    Returns:\n",
    "        str: Confirmation message upon successful sending of the Slack message.\n",
    " \n",
    "    Raises:\n",
    "        ValueError: If the API request fails or returns an error.\n",
    "    \"\"\"\n",
    "    api_url = \"https://slack.com/api/chat.postMessage\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {SLACK_BOT_TOKEN}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"channel\": channel,\n",
    "        \"text\": message\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(api_url, headers=headers, json=payload)\n",
    "        response_data = response.json()\n",
    "        if response.status_code == 200 and response_data.get(\"ok\"):\n",
    "            return f\"Message successfully sent to Slack channel '{channel}'.\"\n",
    "        else:\n",
    "            error_msg = response_data.get(\"error\", \"Unknown error\")\n",
    "            raise ValueError(f\"Slack API Error: {error_msg}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise ValueError(f\"Failed to send message to Slack channel '{channel}': {e}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign tools to their respective groups\n",
    "tool_groups[\"Computation\"][\"tools\"].append(query_wolfram_alpha)\n",
    "tool_groups[\"Automation\"][\"tools\"].append(trigger_zapier_webhook)\n",
    "tool_groups[\"Communication\"][\"tools\"].append(send_slack_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Embed Group and Tool Descriptions\n",
    "# -------------------------------\n",
    "# Embed group descriptions\n",
    "group_names = []\n",
    "group_embeddings = []\n",
    "for group_name, group_info in tool_groups.items():\n",
    "    group_names.append(group_name)\n",
    "    group_embeddings.append(embeddings.embed_text(group_info[\"description\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAISS index for groups\n",
    "group_embeddings_np = np.array(group_embeddings).astype('float32')\n",
    "faiss.normalize_L2(group_embeddings_np)\n",
    "group_index = faiss.IndexFlatL2(len(group_embeddings_np[0]))\n",
    "group_index.add(group_embeddings_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed tool descriptions within each group\n",
    "tool_indices = {}  # Maps group name to its FAISS index and tool functions\n",
    "for group_name, group_info in tool_groups.items():\n",
    "    tools = group_info[\"tools\"]\n",
    "    tool_descriptions = []\n",
    "    tool_functions = []\n",
    "    for tool_func in tools:\n",
    "        description = tool_func.__doc__.strip().split('\\n')[0]  # First line of docstring\n",
    "        tool_descriptions.append(description)\n",
    "        tool_functions.append(tool_func)\n",
    "    if tool_descriptions:\n",
    "        tool_embeddings = embeddings.embed_texts(tool_descriptions)\n",
    "        tool_embeddings_np = np.array(tool_embeddings).astype('float32')\n",
    "        faiss.normalize_L2(tool_embeddings_np)\n",
    "        tool_index = faiss.IndexFlatL2(len(tool_embeddings_np[0]))\n",
    "        tool_index.add(tool_embeddings_np)\n",
    "        tool_indices[group_name] = {\n",
    "            \"index\": tool_index,\n",
    "            \"functions\": tool_functions,\n",
    "            \"embeddings\": tool_embeddings_np\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# -------------------------------\n",
    "# Hierarchical Skill Selection\n",
    "# -------------------------------\n",
    "def select_group(query: str, top_k: int = 1) -> list:\n",
    "    query_embedding = embeddings.embed_text(query).astype('float32')\n",
    "    faiss.normalize_L2(query_embedding.reshape(1, -1))\n",
    "    D, I = group_index.search(query_embedding.reshape(1, -1), top_k)\n",
    "    selected_groups = [group_names[idx] for idx in I[0]]\n",
    "    return selected_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_tool(query: str, group_name: str, top_k: int = 1) -> list:\n",
    "    tool_info = tool_indices[group_name]\n",
    "    query_embedding = embeddings.embed_text(query).astype('float32')\n",
    "    faiss.normalize_L2(query_embedding.reshape(1, -1))\n",
    "    D, I = tool_info[\"index\"].search(query_embedding.reshape(1, -1), top_k)\n",
    "    selected_tools = [tool_info[\"functions\"][idx] for idx in I[0] if idx < len(tool_info[\"functions\"])]\n",
    "    return selected_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM with GPT-4 and set temperature to 0 for deterministic responses\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    " \n",
    "   selected_groups = select_group(user_query, top_k=1)\n",
    "    if not selected_groups:\n",
    "        print(\"No relevant skill group found for your query.\")\n",
    "        return\n",
    "    \n",
    "    selected_group = selected_groups[0]\n",
    "    logging.info(f\"Selected Group: {selected_group}\")\n",
    "    print(f\"Selected Skill Group: {selected_group}\")\n",
    "    \n",
    "    # Step 2: Select the most relevant tool within the group\n",
    "    selected_tools = select_tool(user_query, selected_group, top_k=1)\n",
    "    \n",
    "    if not selected_tools:\n",
    "        print(\"No relevant tool found within the selected group.\")\n",
    "        return\n",
    "    \n",
    "    selected_tool = selected_tools[0]\n",
    "    logging.info(f\"Selected Tool: {selected_tool.__name__}\")\n",
    "    print(f\"Selected Tool: {selected_tool.__name__}\")\n",
    "    \n",
    "    # Prepare arguments based on the tool\n",
    "    args = {}\n",
    "    if selected_tool == query_wolfram_alpha:\n",
    "        # Assume the entire query is the expression\n",
    "        args[\"expression\"] = user_query\n",
    "    elif selected_tool == trigger_zapier_webhook:\n",
    "        # For demonstration, use placeholders\n",
    "        args[\"zap_id\"] = \"123456\"  # Replace with actual Zap ID\n",
    "        args[\"payload\"] = {\"message\": user_query}\n",
    "    elif selected_tool == send_slack_message:\n",
    "        # For demonstration, use placeholders\n",
    "        args[\"channel\"] = \"#general\"  # Replace with actual Slack channel\n",
    "        args[\"message\"] = user_query\n",
    "    else:\n",
    "        print(\"Selected tool is not recognized.\")\n",
    "        return\n",
    "    \n",
    "    # Invoke the selected tool\n",
    "    try:\n",
    "        tool_result = selected_tool.invoke(args)\n",
    "        print(f\"Tool '{selected_tool.__name__}' Result: {tool_result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learned Skill Selection\n",
    "Machine Learned Skill Selection employs machine learning techniques to automatically learn and select skills based on past experiences and task feedback. Generic generative and embedding models are often larger, slower, and more expensive than is necessary for skill selection, so by training specific models on task-skill pairs, you can potentially reduce the cost and latency of this part of your agent-based solution. Both historical data and data samples generated by a foundation model can be used to train your skill selection model. Similarly, you could fine-tune a smaller model to improve the classification performance on your skill selection task. The key drawback is it introduces a new model that your team will need to maintain. Carefully consider the costs before choosing to proceed down this path, as it may require extensive training data and computational resources to achieve optimal performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
