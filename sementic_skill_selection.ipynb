{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Skill Selection\n",
    "Another approach, Semantic Skill Selection, uses semantic representations to identify and select the relevant skill based on their semantic similarity to the task requirements. Ahead of time, each skill definition and description is embedded using an encoder-only model, such as OpenAI’s ada model, Amazon’s Titan model, Cohere’s Embed model, BERT, or others. These skills are then indexed in a lightweight vector database. At runtime, the current context is then embedded using the same embedding model, a search is performed on the database, and the top skill is selected. The skill is then parameterized with a text completion model, invoked, and the response is used to compose the response for the user. This is the most common pattern, and is recommended for most use cases. It’s typically faster than Generative Skill Selection, performant, and reasonably scalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import logging\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI embeddings and LLM\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "llm = ChatOpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool descriptions\n",
    "tool_descriptions = {\n",
    "    \"query_wolfram_alpha\": \"Use Wolfram Alpha to compute mathematical expressions or retrieve information.\",\n",
    "    \"trigger_zapier_webhook\": \"Trigger a Zapier webhook to execute predefined automated workflows.\",\n",
    "    \"send_slack_message\": \"Send messages to specific Slack channels to communicate with team members.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for each tool description\n",
    "tool_embeddings = []\n",
    "tool_names = []\n",
    "\n",
    "for tool_name, description in tool_descriptions.items():\n",
    "    embedding = embeddings.embed_query(description)\n",
    "    tool_embeddings.append(embedding)\n",
    "    tool_names.append(tool_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FAISS vector store\n",
    "dimension = len(tool_embeddings[0])  # Assuming all embeddings have the same dimension\n",
    "index = faiss.IndexFlatL2(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize embeddings for cosine similarity\n",
    "faiss.normalize_L2(np.array(tool_embeddings).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to FAISS-compatible format\n",
    "tool_embeddings_np = np.array(tool_embeddings).astype('float32')\n",
    "index.add(tool_embeddings_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map index to tool functions\n",
    "index_to_tool = {\n",
    "    0: \"query_wolfram_alpha\",\n",
    "    1: \"trigger_zapier_webhook\",\n",
    "    2: \"send_slack_message\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_tool(query: str, top_k: int = 1) -> list:\n",
    "    \"\"\"\n",
    "    Select the most relevant tool(s) based on the user's query using vector-based retrieval.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user's input query.\n",
    "        top_k (int): Number of top tools to retrieve.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of selected tool functions.\n",
    "    \"\"\"\n",
    "    query_embedding = np.array(embeddings.embed_query(query), dtype='float32')\n",
    "    faiss.normalize_L2(query_embedding.reshape(1, -1))\n",
    "    D, I = index.search(query_embedding.reshape(1, -1), top_k)\n",
    "    selected_tools = [index_to_tool[idx] for idx in I[0] if idx in index_to_tool]\n",
    "    return selected_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_parameters(query: str, tool_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Use the LLM to analyze the query and determine the parameters for the tool to be invoked.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user's input query.\n",
    "        tool_name (str): The selected tool name.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Parameters for the tool.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        HumanMessage(content=f\"Based on the user's query: '{query}', what parameters should be used for the tool '{tool_name}'?\")\n",
    "    ]\n",
    "    \n",
    "    # Call the LLM to extract parameters\n",
    "    response = llm(messages)\n",
    "    \n",
    "    # Extract content from the AIMessage object\n",
    "    response_content = response.content\n",
    "    \n",
    "    # Parse the response content as JSON\n",
    "    response_data = json.loads(response_content)\n",
    "    \n",
    "    # Example logic to parse response from LLM\n",
    "    parameters = {}\n",
    "    if tool_name == \"query_wolfram_alpha\":\n",
    "        parameters[\"expression\"] = response_data.get('expression')  # Extract mathematical expression\n",
    "    elif tool_name == \"trigger_zapier_webhook\":\n",
    "        parameters[\"zap_id\"] = response_data.get('zap_id', \"123456\")  # Default Zap ID if not provided\n",
    "        parameters[\"payload\"] = response_data.get('payload', {\"data\": query})\n",
    "    elif tool_name == \"send_slack_message\":\n",
    "        parameters[\"channel\"] = response_data.get('channel', \"#general\")\n",
    "        parameters[\"message\"] = response_data.get('message', query)\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m tool_name \u001b[38;5;241m=\u001b[39m selected_tools[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m selected_tools \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tool_name:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Use LLM to determine the parameters based on the query and the selected tool\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[43mdetermine_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Invoke the selected tool\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# Assuming each tool has an `invoke` method to execute it\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 23\u001b[0m, in \u001b[0;36mdetermine_parameters\u001b[0;34m(query, tool_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m response_content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Parse the response content as JSON\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m response_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Example logic to parse response from LLM\u001b[39;00m\n\u001b[1;32m     26\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Example user query\n",
    "user_query = \"Solve this equation: 2x + 3 = 7\"\n",
    "\n",
    "# Select the top tool\n",
    "selected_tools = select_tool(user_query, top_k=1)\n",
    "tool_name = selected_tools[0] if selected_tools else None\n",
    "\n",
    "if tool_name:\n",
    "    # Use LLM to determine the parameters based on the query and the selected tool\n",
    "    args = determine_parameters(user_query, tool_name)\n",
    "\n",
    "    # Invoke the selected tool\n",
    "    try:\n",
    "        # Assuming each tool has an `invoke` method to execute it\n",
    "        tool_result = globals()[tool_name].invoke(args)\n",
    "        print(f\"Tool '{tool_name}' Result: {tool_result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error invoking tool '{tool_name}': {e}\")\n",
    "else:\n",
    "    print(\"No tool was selected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
